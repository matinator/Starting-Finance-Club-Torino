{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a17dae",
   "metadata": {},
   "source": [
    "# Ridge, Lasso and Elasticnet\n",
    "\n",
    "Ora che abbiamo capito come effettuare la regressione lineare anche con più di una variabile indipendente(MLR), è ora necessario vedere come applicare altri metodi lineari per ovviare ai problemi che possono influire sulle previsioni o sul training, ed essi sono:\n",
    "\n",
    "- collinearità: ovvero la possibilità di due o più feature di presentare una relazione di tipo lineare consistente nel dataset, questo in genere è un bene solo nel caso in cui sia perfetta, altrimenti può portare all'insordenza di problemi\n",
    "- dimensionalità: in alcuni casi potremmo avere un numero di feature molto grandi o addirittura maggiori del numero di samples al suo interno\n",
    "- overfitting  o underfitting: il modello non riesce ad estrapolare relazioni generali a causa della sua complessità maggiore o minore al problema.\n",
    "\n",
    "Per questo motivo, basandoci sempre sulla tecnica **OLS** sono state creati altre tecniche più robuste per la regressione, in genere queste tecniche che andremo ad analizzare si basano sulla __[Regolarizzazione](https://it.wikipedia.org/wiki/Regolarizzazione_(matematica))__ ovvero sull'**imposizione sulla formula di minimizzazione di un termine che penalizzi una specifica condizione legata al problema al fine di ridurne l'errore di generalizzazione**.<br>\n",
    "La regoralizzazione viene imposta attraverso le __[condizioni di Karush-Kuhn-Tucker(KKT)](http://onmyphd.com/?p=kkt.karush.kuhn.tucker)__ dove quindi introduciamo dei termini di penalizzazione sugli unici termini che possiamo controllare: **i pesi($w$)**. In questa lezione vedremo che la condizione sui pesi come **la norma, la norma quadratica di $w$ o la loro condizione ibrida** porta a diversi tipi di regressori esprimibili matematicamente come:\n",
    "- Ridge Regression : $\\large\\min_{w} \\parallel wX - Y \\parallel^2 + \\alpha \\parallel w \\parallel^2$\n",
    "- Lasso Regression : $\\large\\min_{w} \\parallel wX - Y \\parallel^2 + \\beta \\parallel w \\parallel$\n",
    "- Elasticnet : $\\large\\min_{w} \\parallel wX - Y \\parallel^2 + \\alpha \\parallel w \\parallel^2 + \\beta \\parallel w \\parallel$\n",
    "\n",
    "I parametri $\\alpha$ e $\\beta$ sono detti anche **Iperparametri-Hyperparameters** e vengono determinati usando **criteri di statistica o la cross-validation scegliendo tra quelli che minimizzano l'errore di testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39aaf7",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "Iniziamo ad analizzare la __[Ridge regression](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification)__ riportando la formula definita in precedenza, in cui il termine modulo quadro della norma viene anche detto ***termine $l_{2}$***\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\\min_{w} \\parallel wX - Y \\parallel^2 + \\alpha \\parallel w \\parallel^2 \n",
    "\\end{equation}\n",
    "\n",
    "la trattazione può essere vista anche in questo modo \n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\\min_{w} \\parallel wX - Y \\parallel^2 , \\parallel w \\parallel^2 \\leq \\alpha\n",
    "\\end{equation}\n",
    "\n",
    "ovvero la condizione risulta che i pesi che devono soddisfare la **OLS** devono avere un modulo quadro **minore di $\\alpha$** per poter essere ammesi dalla formula, ma qualè l'effetto prodotto dalla $\\alpha$ sui fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d7a293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33bf21a3d8f46b5bfc3ac3d470da1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e313c6e3ec04419f9cf9597beb402784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b360f59467467b96bec74bef073161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, description='α', max=100000.0, step=1.0),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipywidgets import widgets, interactive_output\n",
    "\n",
    "#load the dataset\n",
    "data = load_boston()\n",
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df['MEDV'] = data.target\n",
    "#prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.LSTAT.values, df.MEDV.values, \n",
    "                                                    random_state=0, test_size = 0.2)\n",
    "#define a first regressor\n",
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "#setting plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(X_train, y_train, label = \"train\", color = \"blue\")\n",
    "ax.scatter(X_test, y_test, label = \"test\", color = \"green\")\n",
    "line, = ax.plot(X_train, ridge.predict(X_train.reshape(-1, 1)), label = \"fit\", color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "#define what happens when slider value change\n",
    "def update(alpha):\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train.reshape(-1, 1), y_train)\n",
    "    line.set_ydata(ridge.predict(X_train.reshape(-1, 1)))\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "#define slider\n",
    "alpha = widgets.FloatSlider(\n",
    "        value=1,\n",
    "        min = 0, # min value \n",
    "        max= 1e5, # max value\n",
    "        step= 1, # step \n",
    "        description = \"\\u03B1\") # unicode character for alpha\n",
    "\n",
    "# An HBox lays out its children horizontally\n",
    "ui = widgets.HBox([alpha])\n",
    "#define interactive output\n",
    "plot = interactive_output(update, {'alpha':alpha})\n",
    "#show slider and plot\n",
    "display(plot,ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418f8d1",
   "metadata": {},
   "source": [
    "Quindi possiamo vedere che alzando il valore di $\\alpha$ quello che succede è che i pesi tendono a zero e la linea diventa orizzontaele questo poichè il termine dominante della funzione di regressione diventa il termine di regolarizzazione, in tal caso l'unico modo per ridure complessivamente il valore è fare tendere a zero $\\parallel w \\parallel^2$ ovvero ponendo i termini $w$ nulli o molto vicini ad esso. <br>\n",
    "Questo aspetto può risultare molto efficacie nei problemi in cui il dataset presenta **multicollinearità, ovvero i dati presentano correlazioni tra di loro** e noi vogliamo invece tenere conto di feature quanto più possibili indipendenti e per la **riduzione delle dimensionalità**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f2a92",
   "metadata": {},
   "source": [
    "### Visione geometrica e riduzione della dimensionalità\n",
    "\n",
    "La visione geometrica può essete interpretata partendo dalla formula che otteniamo per la pendenza dei coefficienti ottenibile come:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large y = X \\hat{\\beta}^{ridge} = X (X^{T}X + \\alpha I)^{-1}X^{T}y = \\sum_{i=1}^{p} u_j \\frac{d_{j}^{2}}{d_{j}^{2} + \\alpha} u_{j}^Ty\n",
    "\\end{equation}\n",
    "\n",
    "Ora focalizzandoci sulla formula possiamo notare che se noi consideriamo il caso in cui i dati sono centrati possiamo definire\n",
    "\n",
    "\\begin{equation}\n",
    "    \\large Var(\\hat(B)_j) = \\frac{u_{j}^{T}u_j}{d_{j}^2} \\qquad \\hat{\\beta}^{ridge} = \\sum_{i=1}^{p} \\frac{d_{j}^{2}}{d_{j}^{2} + \\alpha} u_{j}^T y\n",
    "\\end{equation} \n",
    "\n",
    "pertanto il termine $\\alpha$ riduce la proiezione delle direzioni $u_{j}$ che presentano una varianza più bassa, questo vuol dire che più è alto il valore di $\\alpha$ e avremo componenti con varianza sempre più alta. questo principio a simile a quello che vedremo essere come PCA.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    La cosa forse più interessante dela Ridge Regression è la sua capacità di fittare su dati con molte dimensionalità avendo un piccolo numero di dati riuscendo a cogliere gli aspetti fondamentali della struttura dei dati! Per maggiori infor guardate il video qui sotto!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1950f3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/Q81RR3yKn30\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x1b8159eeee0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "#put link yotube video, only final part\n",
    "YouTubeVideo('Q81RR3yKn30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66eed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variance and weights with α = 1000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>-0.087876</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>-0.044061</td>\n",
       "      <td>0.084989</td>\n",
       "      <td>-0.008172</td>\n",
       "      <td>0.454157</td>\n",
       "      <td>0.028739</td>\n",
       "      <td>-0.546187</td>\n",
       "      <td>0.233914</td>\n",
       "      <td>-0.015136</td>\n",
       "      <td>-0.685913</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>-0.718846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>73.986578</td>\n",
       "      <td>543.936814</td>\n",
       "      <td>47.064442</td>\n",
       "      <td>0.064513</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>792.358399</td>\n",
       "      <td>4.434015</td>\n",
       "      <td>75.816366</td>\n",
       "      <td>28404.759488</td>\n",
       "      <td>4.686989</td>\n",
       "      <td>8334.752263</td>\n",
       "      <td>50.994760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
       "weights   -0.087876    0.059909  -0.044061  0.084989 -0.008172  0.454157   \n",
       "variance  73.986578  543.936814  47.064442  0.064513  0.013428  0.493671   \n",
       "\n",
       "                 AGE       DIS        RAD           TAX   PTRATIO  \\\n",
       "weights     0.028739 -0.546187   0.233914     -0.015136 -0.685913   \n",
       "variance  792.358399  4.434015  75.816366  28404.759488  4.686989   \n",
       "\n",
       "                    B      LSTAT  \n",
       "weights      0.006599  -0.718846  \n",
       "variance  8334.752263  50.994760  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Variance and weights with α = 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>-0.116808</td>\n",
       "      <td>0.046003</td>\n",
       "      <td>-0.023762</td>\n",
       "      <td>2.278150</td>\n",
       "      <td>-8.557796</td>\n",
       "      <td>3.755135</td>\n",
       "      <td>-0.010414</td>\n",
       "      <td>-1.280095</td>\n",
       "      <td>0.222038</td>\n",
       "      <td>-0.011526</td>\n",
       "      <td>-0.969288</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>-0.498849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>73.986578</td>\n",
       "      <td>543.936814</td>\n",
       "      <td>47.064442</td>\n",
       "      <td>0.064513</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>792.358399</td>\n",
       "      <td>4.434015</td>\n",
       "      <td>75.816366</td>\n",
       "      <td>28404.759488</td>\n",
       "      <td>4.686989</td>\n",
       "      <td>8334.752263</td>\n",
       "      <td>50.994760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
       "weights   -0.116808    0.046003  -0.023762  2.278150 -8.557796  3.755135   \n",
       "variance  73.986578  543.936814  47.064442  0.064513  0.013428  0.493671   \n",
       "\n",
       "                 AGE       DIS        RAD           TAX   PTRATIO  \\\n",
       "weights    -0.010414 -1.280095   0.222038     -0.011526 -0.969288   \n",
       "variance  792.358399  4.434015  75.816366  28404.759488  4.686989   \n",
       "\n",
       "                    B      LSTAT  \n",
       "weights      0.008535  -0.498849  \n",
       "variance  8334.752263  50.994760  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132bf44744794ed9a9625f3ef5d928f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1755ecae57a4077bf4c500b0e088d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ab80de94a048918918e0fa16d2d8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, description='α', max=1000.0, min=1.0, step=1.0),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "#prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('MEDV', axis = 1).values, df.MEDV.values, \n",
    "                                                    random_state=0, test_size = 0.2)\n",
    "\n",
    "#define a first regressor\n",
    "ridge = Ridge(alpha = 1000)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "#variables used for plots\n",
    "names = df.columns.tolist()[:-1]#exclude last element\n",
    "variance = df.drop('MEDV', axis = 1).var(axis = 0)\n",
    "ypos = range(len(names))\n",
    "\n",
    "#show data model as dataframe\n",
    "#define dataframe\n",
    "df_model = pd.DataFrame(columns=names)\n",
    "df_model.loc['weights'] = ridge.coef_.tolist()\n",
    "df_model.loc['variance'] = variance.tolist()\n",
    "#display dataframe\n",
    "display(\"Variance and weights with \\u03B1 = 1000\")\n",
    "display(df_model)\n",
    "#model with alpha =1\n",
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train, y_train)\n",
    "df_model.loc['weights'] = ridge.coef_.tolist()\n",
    "#display dataframe\n",
    "display(\"Variance and weights with \\u03B1 = 1\")\n",
    "display(df_model)\n",
    "\n",
    "\n",
    "#plot setting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10,6))\n",
    "#first subplot\n",
    "bar = ax1.barh(ypos, ridge.coef_, align = 'center', color = 'red')\n",
    "ax1.set_yticks(ypos)\n",
    "ax1.set_yticklabels(names)\n",
    "ax1.set_xlabel('Weight value')\n",
    "ax1.set_title('Weights of every feature')\n",
    "#second subplot\n",
    "ax2.barh(ypos, variance, align = 'center', color = 'green')\n",
    "ax2.set_yticks(ypos)\n",
    "ax2.set_yticklabels(names)\n",
    "ax2.set_xlabel('Variance value')\n",
    "ax2.set_title('Variance of every feture')\n",
    "plt.show()\n",
    "\n",
    "#define what happens when slider value change\n",
    "def update(alpha):\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    for i in range(len(ridge.coef_)):\n",
    "        bar[i].set_width(ridge.coef_[i])\n",
    "    df_model.loc['weights'] = ridge.coef_.tolist()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "#define slider\n",
    "alpha = widgets.FloatSlider(\n",
    "        value=1,\n",
    "        min = 1, # min value \n",
    "        max= 1000, # max value\n",
    "        step= 1, # step \n",
    "        description = \"\\u03B1\") # unicode character fro alpha\n",
    "# An HBox lays out its children horizontally\n",
    "ui = widgets.HBox([alpha])\n",
    "#define interactive output\n",
    "plot = interactive_output(update, {'alpha':alpha})\n",
    "#show slider and plot\n",
    "display(plot,ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858cd4f7",
   "metadata": {},
   "source": [
    "## Lasso Regression\n",
    "\n",
    "Ora che abbiamo capito come funziona la ridge regression, vediamo ora come funziona la **Lasso Regression**, partiamo dalla sua formula matematica che a differenza precedente predente un termine di norma detto anche ***termine $l_1$***\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\\min_{w} \\parallel wX - Y \\parallel^2 + \\beta \\parallel w \\parallel \n",
    "\\end{equation}\n",
    "\n",
    "la trattazione può essere vista anche in questo modo \n",
    "\n",
    "\\begin{equation}\n",
    "\\Large\\min_{w} \\parallel wX - Y \\parallel^2 , \\parallel w \\parallel \\leq \\beta\n",
    "\\end{equation}\n",
    "\n",
    "Vediamo cosa succede qualora usiamo questo regressore variando il parametro $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4e3fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d43bdd62ec7402a84b454593194c0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d29bbc3ed3d44d2a51bd3f6d7038931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0190f9c2f214a488a6db0c23429819f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, description='β', min=1.0, step=1.0),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "#import the model\n",
    "from sklearn.linear_model import Lasso\n",
    "#prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.LSTAT.values, df.MEDV.values, \n",
    "                                                    random_state=0, test_size = 0.2)\n",
    "#define a first regressor\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "#setting plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(X_train, y_train, label = \"train\", color = \"blue\")\n",
    "ax.scatter(X_test, y_test, label = \"test\", color = \"green\")\n",
    "line, = ax.plot(X_train, lasso.predict(X_train.reshape(-1, 1)), label = \"fit\", color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "#define what happens when slider value change\n",
    "def update(alpha):\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_train.reshape(-1, 1), y_train)\n",
    "    line.set_ydata(lasso.predict(X_train.reshape(-1, 1)))\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "#define slider\n",
    "alpha = widgets.FloatSlider(\n",
    "        value=1,\n",
    "        min = 1, # min value \n",
    "        max= 100, # max value\n",
    "        step= 1, # step \n",
    "        description = \"\\u03B2\") # unicode character fro alpha\n",
    "# An HBox lays out its children horizontally\n",
    "ui = widgets.HBox([alpha])\n",
    "#define interactive output\n",
    "plot = interactive_output(update, {'alpha':alpha})\n",
    "#show slider and plot\n",
    "display(plot,ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca89a3",
   "metadata": {},
   "source": [
    "Come possiamo vedere in questo caso il valore di $\\beta$(nel codice è sempre alpha) porta a **delle soluzioni dei coefficienti che tendono a zero per valori $\\beta$ molto più piccoli rispetto alla ridge**, il motivo è da ricerca il fatto che ***la penalizzazione ora è l1***.\n",
    "\n",
    "### Visione geometrica- Lasso Regression\n",
    "La lasso regression non può essere riespressa come prima a causa del fatto che ora **non si ha una soluzione analitica a causa della non linearità in Y nella definizione**, questo può portare a dei problemi, fortunamente è ancora possibile visualizzare geometricamente il problema con il video qui sotto, rimane pur sempre la questione di capire cosa succede, la risposta risulta essere che il lasso tenda a fornire ***sparse solution, ovvero soluzione con un basso numero di soluzioni diverse da zero.***<br>\n",
    "Questo aspetto è fondamentale poiché grazie ad esso possiamo dire anche che ***il lasso tende a selezionare le feature più importanti e che riducono la varianza del modello sui dati al prezzo di un minimo di bais; per questo motivo la lasso viene anche usata come feature selction algorithm.***\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "L'algoritmo usato da scikit è quello del <a href=\"https://en.wikipedia.org/wiki/Coordinate_descent\">coordinate descent</a>, non dello SGD e questo tipo di algoritmo richiede funzioni convesse.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ffb707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2MBERISGBUYLxoaL2NCOEJjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY//AABEIAWgB4AMBIgACEQEDEQH/xAAcAAEAAgMBAQEAAAAAAAAAAAAAAQQCAwgFBgf/xABDEAACAgIAAwQDCwsEAgMBAAAAAQIDBBESITEFE0FRImFxBhQyNVJygZGxwdEVFiMzQlRjkpOh4UNic/A0okSC8ST/xAAZAQEBAQEBAQAAAAAAAAAAAAAAAQIEAwX/xAAkEQEBAAICAgIDAAMBAAAAAAAAAQIRAyETQRIxBCJRYYHhFP/aAAwDAQACEQMRAD8A/PzoA5/OgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHP50Ac/gDoA5/OgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHP50Ac/gDoA5/OgAAAAAAAAAAAAAAAAAABAEggASAAABAEggASCABIBAEggASAAAAAAEASCCQAAAAAAAAAAAAAAAAAAAAAAAAAAAHP50Ac/gDoA5/OgAAAAAAAAAAAAAAAAABBJAFHtDtKODk4VMq3N5Vvdpp/B9ZbttrorlZdOMIRW3KT0keB7qu/rv7LyacS/JVGQ5yjTByeteojN7Sy+0excidHZORC2uUdV5FPN/7ox8Wj0+G5Km3tVdo4d1Er6sqmdUPhTjNNL6RT2jh30zupyqbKofCnGaaX0nxuL2bdKrtuvJxM+yq9VTr9DhnPW968N9ORZxMS/I7L7UqysC+dUlFQnGlVXXa11XLev7m7x4/wBNvqsbPxMuEp42TVbGHwnCaaQxs7FzHJYuRVc4/C4JJ6PlMPEz8js7tWiGNOLlUo1XW091ZPl8F+ftLPYuNdZ2zjZFeFbiU0YvdW95Dg45erz9pLxyb7NvS7Y7cfZubjYlWFblXZCk4xraT5dTVje6ON1eZ3uJZj34sVKdVs1Hk/8Ad0RV90XZlnaXui7LjrIhQoWqd1W1wcuXpeG2efHs6/E7K7awZYl9uTKHoZHDKXfx8FvzXkjWOGFxm/v/AKm6+qu7TxqMeFl11dc7IccYOa3LlvS8zXhds4uR2Xj510440L/gqySXjrR4GRi31ZsLbsC7Jrs7PVUIxr4uCevHyK+NhZNGL7nrrsS6yvHVkbaeBuSb3puJJx42Lt9fHtHCnRO+OVS6q5cM5qa1F+TZsx8mjLqVmNdC2HyoSTR8DiYWRl9hZHvWqaVXasrJ1RipPhSjyS8deXqPpfczizpszciSyUr5p/p6lXtpdVFdP8Ez45jLdmzK90dtXamTg43Zl+VLG4eOVcl4raLfZnbeLn9nzzG+4jXNwsVr1wSXVN/SeBldg39o+6Htmzjysb0a3TZHcYzfCvHx6GqzAyb/AHNUU0YF2NbjZSnfXwNuzXWS4vhef0G/hhZP9JuvsKs3Fuod9WRXOpdZxkml9Jrh2r2fZvgzaJcMHY9WJ6iusvZ6z5WfZeVf2J2vKhZXeZLi0rqlVx666ium1yK81747YzY0YVtEp9jTjGpw1KT6dP7fQScUvtdvs4dpYNlM7oZdMq4acpqa0t9OZnXnYluO8ivIqlSutimnFfSfK5XZWTL3J9mQoonCyqVdl1ah6bS6+i+r570yaezHb2X2rK2jPthkuL4HVGqcmvGMfx8jPjx1vZt9PT2jhZFU7acqmyuHwpRmmo+00z7XxJYd+Ri305CpW5KNsUvpfRHzmBi339ndqU5OBfKqUIxhZ3KqutXk1y3o00Y+ZPsrtar3la4vHUarJ4/BbN/J1r0tF8U/pt9a+0sWnHptyb6qO9inFTsXPa8H4md3aGHjuCuyaq3YnKHFNLiS6tHyt2JkUZeNkX4N2TTLs5UKEK3Jws0uq8PIjF7Jy6sr3NVZdE7VRC3vXwuUYb5xTfh4L6CTjx1vZt9fj5NOVUrce2Ftb6Sg9o2Hge5PHtxqe0YW0zqTzbHWpRcdx5aa9R7555TWVkVIAMgAAAAAAAAAAAAAAAAAAAAAHP50Ac/gDoA5/OgAAAAAAAAAAAAAAAAABBIAjQJAEaBIAjQJAEaGiQBGiln9lYnaMq55EJcdW+CcJuMo7680XgWXXcFbCwcfAx1Ri18Fabet7234tlgkEvYjQ0SANGZiUZuNPHya1ZVNalFlfB7Iw8C2VtEJuya4XOybnLXltl8F3ZNCBokEEaGiQBGgSAI0CQAAAAAAAAAAAAAAAAAAAAAAAAAOfzoA5/AHQBz+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEACQQAJBAAkAAAAAAAAAAAAAAAAEACQQAJAAAAAAAAAAAAAAAAOfzoA5/AHQBz+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAA1XXwq0pPcn0iubZq4Lr/1su6h8iL5v2v8AAm102WZNNb1Ka4vkrm39Bj77io8XdXcPn3b+zqbK6a6lqEEjYOzphCyNkVKElJPxRmV6oqGVdGPKLSlr1lgpZpIACAAAAAAAAABAEkDZXnkuUnDHj3klyb/ZX0hZNt8pKK22kjQ8uri1Bysf8OLl9gji8bUsibtl5dIr6DekorSSS9RDppWVDjUJKcG+nHHSf0m5GF9cbKZxl0aIxZuzFpnLk5QTf1Av9jcACoAAAAAAAAAAAAABz+dAHP4A6AOfzoAAAAAAAAAAAAAAAAAAAAAAAAACACGwJZWnfKc3XjpNr4U30j+LMXKeVJxrbjSuUprrL1L8Rx/6OJGKUeTm/gx/Fk21IlRpxfSnLislycnzkyVZfY/0dKhH5Vj5/UaapQjJuiEsizxsf4/gbXdbVKLuhHglJR3F9G+hFsT3t1dkY3Ri4yelKPg/YWSvlPnVBdZTX9uYyrJRrUIfrLHwx+9lTW9Ixf0ll13hKXCvYv8AOyyYVVqquMI9IrSMyxL9pAAQAAAAACCSGAMLJxri5TekvEi62NMOKXPwSXVs0Rrcn32U0uHmo75Q/wAk2shw2ZXOW66fk9JS9vkbJW046UF9EILb+pGizIlZHi4+5p+V+1L2ImnjjH9Bj8EX+1Y+b+/6yba1/W1W3tbWO0v900mZ03K6L5OMovUovqmRTa5SlXZHhnH17TXmY0NSychronGP06/yVE5c3HHko/Cl6K9r5G2uPBCMfkrRX/X5e/8ATp/vJ/h95aES9TSQAVAAAAAAAAAAAAAAOfzoA5/AHQBz+dAAAAAAAAAAAAAAAAAAAAABBjXbC1Pu5qWnp6fQDMg1SyK1lRxuL9LKDml6k0vvNoDZUbeZJxTaoi+bX7f+CbG8qbqg9VR5TkvH1L7zXdZGalBPgor5TkvH/ajNbkLbYyg1GXd40fRcl1l6kZV0O1JWR7ulfBqX3/gZUUuco22x4eH9XD5C/EsiQt11BJRSUVpLokV8r03VUusppv1JPb/76zfOahFyk9JLbZQ3O+165SsX8kPxZamM9t1Uu9unkSeq4Lhh97/75E48XbY8iS1vlBPwj/kw4VkSVEF+gr5Tfm/L8S6lpCFoCQVkAAAEGrHyasmDnTNSivEDcQY97DvVXv02uLXqMgBqvujTDilt+CS6t+RlbZGqtznySK8FreVkai0uSf7C/EiyCiq08nJa4/BfJ9SNM5TusSlDil1jU+kV5yDlZddF8Ppv9XF9IL5T9ZcpqVMdLm3zlJ9WyfbdumNWOoy47Hx2/Kfh7PI3A0ZNsopV1/rZ8l6vWX6Y7rU7lGd9/VLUI+t//pl6WPjxrhzus3r2vqzVXwKKsf8A49PwP9z8yxj1ycnfbynLkl8leRG702UVKmpQXPzfmzYCTTzAAAAAAAAAAAAAAAADn86AOfwB0Ac/nQAAAAAAAAAAAAAAAAAAAARLnFnl9n4uRhRgtb7yS7xdeHS1vbfs6HqAClbVW+2ce1wi7FRYlLXPXFD8WbcicpSVFT1OXWXyV5mnLtVOfTN8/wBBZpeb4ocjdRX3NUrLX6cvSm/++BKs/rCz9HCGLRylJdfkrxZjTXG2xKK/Q08or5UvFkblHGsvf623UY78N8o/aWqa1VVGEekURq3UVMvKjTnY9bjJ8T+Eui29f92bqcSvHyL8hTscrmnJSntLXkvAjIqx1bHJv6wWlvp13089mi6yzInwcHJ9K/P1y8l6i2pMdl1zyZxVa4o79CPy/W/9pmouO6KZbslzts8v8+QinXJ1UtTvl8OeuUV/3wLVNUaYcMfHm2+rfmTTVsiaq41QUIrSRmAaeaQAAAAEHmdndn3YGPRXGaetd7wrS5R1/wB6HpgCk8et9sxyGn3kaHFPietOS8OngXWyu/jBf8X3mOQ3dYseL5Nbsa8I+X0hZNor/wD6rVa991B+gvN+ZrvtVjc2uKmp6il/qT8F9f8Ac35MnCuNVfKVj4I68PWYKuPvmupfApjxa9fh95lqf1sxquCLlPnZPnJ/cUapV9pLNxZK2EW3FyUnFvTa2n9HgeoUoQpw5zjjw47rJOTW/Nt834LmX6Z7tbnKOJRCtcU2lwwW9uRVUXZOfFNc/wBdYnyS+ShFSslKXec/9S3wivKP4m2qpXqPDHhx4/Bj8v1v1E+25+rKqDvlGxx4aYfq4dPpZbCBWLdhJBJUAAAAAAAAAAAAAAAADn86AOfwB0Ac/nQAAAAAAAAAAAAAAAAAAAACGSYWSUYOT6JbYHn2av7cp2uVNVmnvrLcN/cWs3/xpR3riai/peitjxccvFbT4pUWylvzcoF62uNtcoS6SWiemvqsLqlbTwb4WtOL8muhrbyVH0pUwS6y5v8AsSq8qMeFXQfrcOf2kSorgu8yLHZw89zfJfQBohCV0+Ktuf8AGn0XzV95sjybpxfhft2vnp/ezJd5lco7qp8+kpezyRZhXGuCjBKMV4Iki2saaY0w4Y/S31b9ZsANMJAAAAAAAABAAq2zjVmOcnyjS2/rM8Stxrc7Fqyx8UvwKuW+PtWinwnByfsTT+3R6BF+orpcWc2/2IaX0v8AwibK7Fd3tLjtrUoy8SbarFb3tLjvWpRl0aMWsqfJd3WvPnJhWFveqO77o1Q8odfrNagu7badFHV7fpz9r6/ebJRqomnLivvfRPm/o8kZ148pyVuQ05L4MF0j/n1ka3qMK6nfwuUe7oj8Cvpv1v8AAuJaGgWMW7CSCSoAAAAAAAAAAAAAAAAAAAc/nQBz+AOgDn86AAAAAAAAAAAAAAAAAAAEASacuDtxba4vTlFpM2mNk1CPFJ8glsndU4WxtzsWcejos+j0oF1yUU22kl4s8O1p9q1TjuG6rNqL1vnA9KrHx7FxtOx9fTk5a+stxsYw5uPO6lZPK4+WPB2v5XSK+kQxm5qd8u8kui/Zj7EWEkiTOnrv+CJIJKgAAAAAAAACAABhZZGuO5MpWZVkuj4UamNrw5efDj+y+fB2zj7XJ1SXF5PaPQPEk3LM1J7Xd+PtN3E3ylKbXkpNF8deX/tw3JY9G2+upfpJqO+i8zS5338q4uqHjOS9J+xfiTixo5yrglPx3zf1llGNX27McsbN4tVNEKk+Fek+sn1ZtAAkAAAAAAAAAAAAAAAAAAAAAAAA5/OgDn8AdAHP50AAAAAAAAAAAAAAAAAAINdt9dLSslrfTk2a5Z2Oot8b5f7X+AG2ycYRbkzz7bZWy2+ngjTbn12y25vXguFmHvqn5b/lZ74Yyd18r8jlz5L8cZ0xn8YU/wDFZ9sC1XZKuW19R588qn3/AEvi/wBKf7L84Fj31T8v/wBWa6rw1njZY9mqyNkeKLMzxas6quW1N68Vws9CGfRKKfE1v/a/wPDLHT6vBy+SdztaJK/v3H+W/wCV/gPfuP8ALf8AK/wMvdYBX9+4/wAt/wAr/Ae/cf5b/lf4AWAVcLPozlJ0d56L0+OuUN+za5loAAAIIb0tmFuRXU0py036mzTbm0d1LU30f7LCW6m1e+x2WN+C6Gs0++qflv8AlY990/Lf8rOmaj4WUzyyuVP/AJq/4/vNxT99U+/E+P8A0/kvzN3vqn5f/qxLDLDLf0sVzdc1JHpwkpRTXieJ77p+X/6sv4ubR3CTm/5WefJr7dv4VyluN+l4Ff37j/Lf8r/Ae/cf5b/lf4Hk+isAr+/cf5b/AJX+A9+4/wAt/wAr/ACwCtg5+N2hT3uLarIb02vBlgCQAAAAAAAAAAAAAAAAAAOfzoA5/AHQBz+dAAAAAAAAAAAAAAAAAAQNEkAUsnH4fTguXiiset1KWTRw7nBcvFHthn6r5v5P42v3wedP4wp/4rPtgWCvP4wp/wCKz7YHoY1HG+KXwftN705MePLkykhj4/G1KS9H7S8lroQuXJGR4ZZbr7HFxY8eOogEgy9VHtW+zHxVKqSjJzUdt61ssYtvfY8JP4TinJeKbWzZKEZa4knp7XtIhXGEpyjvc3t8/HWvuAy0SAAAAEGNi4q5LzRkAlm5p5LWnp9QWcqhqTnFcvErHTjdx8Ll47x5arT/APNX/H95mrYOx1qXprm0YP8A8xf8f3lW+l233OuXBZDhcJevX2Faxw+eWv8AD0D0saPDTFPqeV2VZ783xrhnW9Ti/Bnso8uTL07fxOG425ZAJB5O9hbJwqnJdVFtFHsfLnlY27pqU+q14rS/E9BpNNPozBUwjOM0tOMeFeSX/UBmkl0WgSAAAAAAAAAAAAAAAAAAAAHP50Ac/gDoA5/OgAAAAAAAAAAAAAAAAABBIAgNciSAPOsxY/lah+Hc2PX0wPRSSXIrzrm8+mxL0I1Ti3624a+xlgtu2ccMcfqBIBGgAAAAAAAAAAQCQBBXsxYSe16L9RYNGbY6sO6yPWMW0WWz6Yzwxzmso8q6Mllt1OMlGPC5Pkk9/wBzXGLU5zlKLc9dF5GS5RS8EgdeOP8AXJ8cZf1jDglHIjfTJQtjye1ykvJl1doZH8H6mVQLx427bmeUmlr8oZH8H6mPyhkfwfqZVBPFivlyWvyhkfwfqY/KGR/B+plUDxYnlyWvyhkfwfqY/KGR/B+plUDxYnlyWvyhkfwfqY/KGR/B+plUDxYnlyWvyhkfwfqY/KGR/B+plUDxYnlyWvyhkfwfqY/KGR/B+plUDxYnlyWvyhkfwfqZnV2olZGvJgq+J6jNPcW/L1FI1ZMFZj2Rl0cTN4prpZy32+jXMkodi3zv7NpnY9ycFtl45nSkAAAAAOfzoA5/AHQBz+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQVu0vi7I+YyyVu0vi7I+YwleUY2WRrSc3pN62ZGu6DlwaXSabO704/bHHyacmhXVTTrk9J76mzvIa3xx1z8fLqVve8/yXCnS72NcUlv9pJfeVKuz74xsUktajKOn1e05L61/cm61qPUhONkeKuSlF+MXtGKvpk5KNsG4/CSkuXtMMWDjGblCUXKW/Tkm+mvDkUY4uROf6SrS7mUGtx1tuPJJeHJ9RbU1Ho9/T6P6WHpvUfSXP2GU5wrjxWSjGPnJ6RUycecrpNQnKE4KGoyUUub6/X4G/IjJuucYcfBLbimtvk14l3TUSsmlwU3ZGMZNxTk9baeiZX1Q252Rgk9bk0vDZSrx7a6Ne903KMo8CktQ3Jv6uZtqxZLI4pxTSnxJ/8A0ivuZN1dRYlfVCMZSthFS6NyXMynZCuPFOcYrzb0eVlx7mi2Eq4zc6XFQcktc39u108j0LqnZLHek1CfE9/Na+1obpqM3fVGKlKyMU3pNtLbIWRTqDdkY8aTipPTaK0qLIJvuVbvvFw7X7Utrr4FexOqtUyrjOb7r9pejrX4eA+VNR6isg7HWpxc0tuO+a+gyKVOPZDJ9OM2lZOanxLh578Ovjoull2zegwt/VT9jMzC39VP2MtIve574qp+aj1Dy/c98VU/NR6hwO0AAAAADn86AOfwB0Ac/nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFbtP4uyPmMslbtP4uyPmMRK8o13WxpgpSUntqKUVttmwwshx8PPXDJSO704/bWsqHeKDjJc0m3rSfkYPPqjtuNnCoSmpcPJpddE+9dZLtTgk5cT3XuW/aVo411r7puUalXOC4odN9Oe+ZN1rUWp5kIL0oTXLilyXorzZPvqDtnWozfB1klyXLZjkYne3d5GUE3FRfHDi5Jvp5dWRLEbzFf3iWk+ShzfLWm/FDtOmVeXGyMJKMoqT0uJdeTf3EPNrUXKULEuHiXo/CXq+tfWYU4Lre3ZH4fFqMOFdGum+vMlYcvRU7U1CPBDUdaW0+fPn0Q7X9W+m5W8S4JQceqkjC/Mpx21a2ta8PN6M3CUZynBpuTjtPwXiacvCjlTjKU3FKMotJddrRe9J0meZTv4Llw729L0VvW/7P6jdbZwQUuGUtvWorZVXZ+lDhnFyUFGUp1qW+e9ryfNm/Kod9cYKSjqW+cdp+prkSbLpjDMhNwUYWNy3y1009PZNORVdPSi964ot69JeaMcXE97xiuPi0pdI66y2MXF978k4cKjwxUa+F/S/EdnSyADTIYW/qp+xmZhb+qn7GKq97nviqn5qPUPL9z3xVT81HqHA7QAAAAAOfzoA5/AHQBz+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQVu0/i7I+YyyVu0vi7I+YwleUasq2dVPHCPE01vk3peekbTGyuNsOGe9eptP60d3px+1R5s3GHBFSbhxPhjKSfPp6vpEsqyNlkdNvvNR9Fy4VwRfRe03PEoUIx4WlFaWptcuvPnzJljUz3yabfFuMmnvWuq9SJqtbjCF91k4xjCMWoxlNT2ura5fUzRHJvhW3LhnLVrXguUkl9paeNU3B8L9DktSf9/P6SPetC2+F+lve5Pxe34+aFlJYw7+6M3VKNfeNxSa3rnv8GZ0WznROVihGUXJcny5C+jvE3FR4m1tttdPZ06jGxlTjuqWmpNuX0+0dp0wxMqV1s4S4XqKltRa6+32Guq615a4nLu5ynHw4dptJefRFinFqok5VqXFJJNyk5cl7WY04ldc3Y9ubnKXwnrm34dN6Y1V6acm3Ihfeq5R1GuDjF+bcl1+gznkW1xmp92pRklvnrn6vM3Tx67LOOSfFpL4TW0ufQW41VvOae9p7UmntetDVNxXxci7IthLcVDhmpLT6qWt8zKzIlXbPe3GMunq4NmyrEpp4O7i1wb16T8Xt78zN01uXE47e9/219g1TcVvfd/c2TVLbSTXoSXV8+vXSLGNb31EZtxe9/B3r+5isSlQlHUtS1v05b5eXPkbKqoU1qFaaiufN7+0slS6ZmFv6qfsZmYW/qp+xlqL3ue+Kqfmo9Q8v3PfFVPzUeocDtAAAAAA5/OgDn8AdAHP50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBW7S+Lsj5jLJW7S+Lsj5jCV5RU7Runj4/ewb9F80lve+S/votg7vTj9vHhZfZXwW2SbjJ1N61tqE+f08jZrVd11V82oURcdS2m1xM9QaRPi18lFKduTGHezhH9I2o8t6cdfaRZLvezMey2bjvupSknrxRfA+J8nn0KUOGcbZtSvsXDvlrcvwMuz7bbZenODbhuUVNyaf1LXjyLw0hMUuW3nWXzhnTg7dpp8KjL4Po75rX9zVxu3HjGORKziVblLxjLjX1ew9WUVJNPxWhGKjFRS5LkPivyULp21cUI2birUnKc+HS4d9dPxMqpWzcW7eLhr4lwvalzeufiXtAfE+Sjg3Tk5OyyDSjuSVnFp/UtF4aQLJpm3YACoGFv6qfsZmYW/qp+xiqve574qp+aj1Dy/c98VU/NR6hwO0AAAAADn86AOfwB0Ac/nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFXtL4uyPmMtGrKq7/Gsq6ccWgPGBppv23VZ6F0OU4vwZt2vNHdLuOKpBG15ja8yokEbXmNrzAkEbXmNrzAkEbXmNrzAkEbXmNrzAkEbXmNrzAkEbXmNrzAkwt/VT9jMtrzKmdkqNfc1endZ6MYoluosm69f3PfFVPzUeoUOx8d42BVU3vhilsvHC7UgAAAABz+dAHP4A6AOfzoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQSAKHaHZONntSsi42LpOL4ZfWUPzaq/eMj+oz3QXdTTwfzar/eMj+ox+bVf7xkf1Ge8Bumo8H82q/3jI/qMfm1X+8ZH9RnvAbpqPB/Nqv94yP6jH5tV/vGR/UZ7wG6ajwfzar/AHjI/qMfm1X+8ZH9RnvAbpqPB/Nqv94yP6jH5tV/vGR/UZ7wG6ajwfzar/eMj+ox+bVf7xkf1Ge8Bumo8H82q/3jI/qMfm1X+8ZH9RnvAbpqPB/Nqr94yP6jLWD2Jj4c3OKcpvrKT239J6gG6agkktIEgigAAAAAc/nQBz+AOgDn86AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAc/nQBz+AOgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHP4AH/2Q==\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/14MKVkhvMus\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x1b815bfd3a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put link yotube video, only final part\n",
    "YouTubeVideo('14MKVkhvMus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d1d142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variance and weights with β = 100'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.023137</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>73.986578</td>\n",
       "      <td>543.936814</td>\n",
       "      <td>47.064442</td>\n",
       "      <td>0.064513</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>792.358399</td>\n",
       "      <td>4.434015</td>\n",
       "      <td>75.816366</td>\n",
       "      <td>28404.759488</td>\n",
       "      <td>4.686989</td>\n",
       "      <td>8334.752263</td>\n",
       "      <td>50.99476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
       "weights   -0.000000    0.000000  -0.000000  0.000000 -0.000000  0.000000   \n",
       "variance  73.986578  543.936814  47.064442  0.064513  0.013428  0.493671   \n",
       "\n",
       "                 AGE       DIS        RAD           TAX   PTRATIO  \\\n",
       "weights    -0.000000  0.000000  -0.000000     -0.023137 -0.000000   \n",
       "variance  792.358399  4.434015  75.816366  28404.759488  4.686989   \n",
       "\n",
       "                    B     LSTAT  \n",
       "weights      0.004687  -0.00000  \n",
       "variance  8334.752263  50.99476  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Variance and weights with β = 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>-0.058890</td>\n",
       "      <td>0.053177</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.679550</td>\n",
       "      <td>0.016841</td>\n",
       "      <td>-0.648766</td>\n",
       "      <td>0.198738</td>\n",
       "      <td>-0.013994</td>\n",
       "      <td>-0.864220</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>-0.73121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>73.986578</td>\n",
       "      <td>543.936814</td>\n",
       "      <td>47.064442</td>\n",
       "      <td>0.064513</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>792.358399</td>\n",
       "      <td>4.434015</td>\n",
       "      <td>75.816366</td>\n",
       "      <td>28404.759488</td>\n",
       "      <td>4.686989</td>\n",
       "      <td>8334.752263</td>\n",
       "      <td>50.99476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
       "weights   -0.058890    0.053177  -0.000000  0.000000 -0.000000  0.679550   \n",
       "variance  73.986578  543.936814  47.064442  0.064513  0.013428  0.493671   \n",
       "\n",
       "                 AGE       DIS        RAD           TAX   PTRATIO  \\\n",
       "weights     0.016841 -0.648766   0.198738     -0.013994 -0.864220   \n",
       "variance  792.358399  4.434015  75.816366  28404.759488  4.686989   \n",
       "\n",
       "                    B     LSTAT  \n",
       "weights      0.006603  -0.73121  \n",
       "variance  8334.752263  50.99476  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776315e30e5e4fc5b5d587e0cc66d0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ada250e3d54885b632c245cab7139d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa89079f5f84b6b8c6b1f840a91922d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, description='β', min=1.0, step=1.0),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('MEDV', axis = 1).values, df.MEDV.values, \n",
    "                                                    random_state=0, test_size = 0.2)\n",
    "\n",
    "#define a first regressor\n",
    "lasso = Lasso(alpha = 100)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#display dataframe\n",
    "df_model.loc['weights'] = lasso.coef_.tolist()\n",
    "display(\"Variance and weights with \\u03B2 = 100\")\n",
    "display(df_model)\n",
    "\n",
    "#model with alpha =1\n",
    "lasso = Lasso(alpha = 1)\n",
    "lasso.fit(X_train, y_train)\n",
    "df_model.loc['weights'] = lasso.coef_.tolist()\n",
    "#display dataframe\n",
    "display(\"Variance and weights with \\u03B2 = 1\")\n",
    "display(df_model)\n",
    "\n",
    "#plot setting\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "#first subplot\n",
    "bar = ax.barh(ypos, lasso.coef_, align = 'center', color = 'red')\n",
    "ax.set_yticks(ypos)\n",
    "ax.set_yticklabels(names)\n",
    "ax.set_xlabel('Weight value')\n",
    "ax.set_title('Weights of every feature')\n",
    "\n",
    "#define what happens when slider value change\n",
    "def update(alpha):\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    for i in range(len(lasso.coef_)):\n",
    "        bar[i].set_width(lasso.coef_[i])\n",
    "    df_model.loc['weights'] = lasso.coef_.tolist()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "#define slider\n",
    "alpha = widgets.FloatSlider(\n",
    "        value=1,\n",
    "        min = 1, # min value \n",
    "        max= 100, # max value\n",
    "        step= 1, # step \n",
    "        description = \"\\u03B2\") # unicode character fro alpha\n",
    "# An HBox lays out its children horizontally\n",
    "ui = widgets.HBox([alpha])\n",
    "#define interactive output\n",
    "plot = interactive_output(update, {'alpha':alpha})\n",
    "#show slider and plot\n",
    "display(plot,ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb888c",
   "metadata": {},
   "source": [
    "## ElasticNet\n",
    "\n",
    "Ora che abbiamo visto come funzionano la Lasso e la Ridge regression, vediamo la __[ElasticNet Regression](https://core.ac.uk/reader/4406480)__ che è un intermezzo tra le due regressioni precedenti e assume la formula:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Large \\min_{w} \\parallel wX - Y \\parallel^2 + \\alpha \\parallel w \\parallel^2 + \\beta \\parallel w \\parallel\n",
    "\\end{equation}\n",
    "\n",
    "dove quindi abbiamo un **termine di regolarizzazione sia su il modulo quadro di $w^2$ che il modulo $w$**.<br>\n",
    "La formula di scikit per l'elasticnet è leggermente diversa ed è del tipo:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large \\min_{w} { \\frac{1}{2n_{\\text{samples}}} ||X w - y||_2 ^ 2 + \\alpha \\rho ||w||_1 +\n",
    "\\frac{\\alpha(1-\\rho)}{2} ||w||_2 ^ 2}\n",
    "\\end{equation}\n",
    "\n",
    "in questa formula il termine $\\rho$ deve essere un numero compreso tra 0 e 1 e ci dice in che misura contare i termini L1 e L2, metre $\\alpha$ è il solito termoine di penalizzazione.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    Nel 2014 è stato scoperto che Elasticnet è come una Support Vector Machine lineare, vedremo in seguito cosa sono!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354246eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3a98bf5c9a4953865591ad56bb9c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64acaa2f10cf41869d1d9493afbe1c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664754c387704c5892c56481ee0802b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, description='α', max=1000.0, min=1.0, step=1.0), FloatSlider(value=0.5, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "#prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.LSTAT.values, df.MEDV.values, \n",
    "                                                    random_state=0, test_size = 0.2)\n",
    "#define a first regressor\n",
    "elastic = ElasticNet(alpha = 1, l1_ratio = 0.5)\n",
    "elastic.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "#setting plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(X_train, y_train, label = \"train\", color = \"blue\")\n",
    "ax.scatter(X_test, y_test, label = \"test\", color = \"green\")\n",
    "line, = ax.plot(X_train, elastic.predict(X_train.reshape(-1, 1)), label = \"fit\", color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "alpha =  widgets.FloatSlider(value=1, min = 1, max= 1e3, step= 1, description = \"\\u03B1\")\n",
    "rho =  widgets.FloatSlider(value=0.5, min = 0.01, max= 1, step= 0.01, description = \"\\u03C1\")\n",
    "\n",
    "#define what happens when slider value change\n",
    "def update(alpha, rho):\n",
    "    elastic = ElasticNet(alpha = alpha, l1_ratio = rho)\n",
    "    elastic.fit(X_train.reshape(-1, 1), y_train)\n",
    "    line.set_ydata(elastic.predict(X_train.reshape(-1, 1)))\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "# An HBox lays out its children horizontally\n",
    "ui = widgets.HBox([alpha, rho])\n",
    "#define interactive output\n",
    "plot = interactive_output(update, {'alpha':alpha, 'rho':rho})\n",
    "#show slider and plot\n",
    "display(plot,ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bfd6e",
   "metadata": {},
   "source": [
    "### Interpretazione geometrica dell'elasticnet\n",
    "\n",
    "L'elasticnet può essere visto come un'intermezzo tra la ridge e il lasso, dal punto di vista geometrico potete interpretarlo con questa immagine:\n",
    "\n",
    "![Elasticnet geometrical view](../img/elasticnet.png)\n",
    "\n",
    "il parametro $\\rho$ nella formula ci dice come vogliamo sia la formula di penalizzazione, con il parametro uguale a 1 abbiamo un lasso, mentre con zero abbiamo un comportamento ridge, con 0.5 abbiamo un comportamento intermedio tra i due."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96770a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variance and weights with β = 100, ρ = 0.5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.023099</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>73.986578</td>\n",
       "      <td>543.936814</td>\n",
       "      <td>47.064442</td>\n",
       "      <td>0.064513</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>792.358399</td>\n",
       "      <td>4.434015</td>\n",
       "      <td>75.816366</td>\n",
       "      <td>28404.759488</td>\n",
       "      <td>4.686989</td>\n",
       "      <td>8334.752263</td>\n",
       "      <td>50.99476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
       "weights   -0.000000    0.007871  -0.000000  0.000000 -0.000000  0.000000   \n",
       "variance  73.986578  543.936814  47.064442  0.064513  0.013428  0.493671   \n",
       "\n",
       "                 AGE       DIS        RAD           TAX   PTRATIO  \\\n",
       "weights    -0.000000  0.000000   0.000000     -0.023099 -0.000000   \n",
       "variance  792.358399  4.434015  75.816366  28404.759488  4.686989   \n",
       "\n",
       "                    B     LSTAT  \n",
       "weights      0.010668  -0.00000  \n",
       "variance  8334.752263  50.99476  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Variance and weights with α = 1, ρ = 0.5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>-0.079223</td>\n",
       "      <td>0.056378</td>\n",
       "      <td>-0.024847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.842704</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>-0.757884</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>-0.014712</td>\n",
       "      <td>-0.856892</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>-0.714712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>73.986578</td>\n",
       "      <td>543.936814</td>\n",
       "      <td>47.064442</td>\n",
       "      <td>0.064513</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>792.358399</td>\n",
       "      <td>4.434015</td>\n",
       "      <td>75.816366</td>\n",
       "      <td>28404.759488</td>\n",
       "      <td>4.686989</td>\n",
       "      <td>8334.752263</td>\n",
       "      <td>50.994760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM          ZN      INDUS      CHAS       NOX        RM  \\\n",
       "weights   -0.079223    0.056378  -0.024847  0.000000 -0.000000  0.842704   \n",
       "variance  73.986578  543.936814  47.064442  0.064513  0.013428  0.493671   \n",
       "\n",
       "                 AGE       DIS        RAD           TAX   PTRATIO  \\\n",
       "weights     0.015518 -0.757884   0.228696     -0.014712 -0.856892   \n",
       "variance  792.358399  4.434015  75.816366  28404.759488  4.686989   \n",
       "\n",
       "                    B      LSTAT  \n",
       "weights      0.006905  -0.714712  \n",
       "variance  8334.752263  50.994760  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe3b0b85474f6598e8a795cefe94a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f623491ed0894d9aaadc5bf018161f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0d41fcd3a24bbc9176c1ffb4c978cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=1.0, description='α', min=1.0, step=1.0), FloatSlider(value=0.5, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prepare the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('MEDV', axis = 1).values, df.MEDV.values, \n",
    "                                                    random_state=0, test_size = 0.2)\n",
    "#model with alpha =100\n",
    "elastic = ElasticNet(alpha = 100, l1_ratio = 0.5)\n",
    "elastic.fit(X_train, y_train)\n",
    "df_model.loc['weights'] = elastic.coef_.tolist()\n",
    "\n",
    "#display dataframe\n",
    "display(\"Variance and weights with \\u03B2 = 100, \\u03C1 = 0.5\")\n",
    "display(df_model)\n",
    "\n",
    "#define a first regressor\n",
    "elastic = ElasticNet(alpha = 1, l1_ratio=0.5)\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "#display dataframe\n",
    "df_model.loc['weights'] = elastic.coef_.tolist()\n",
    "display(\"Variance and weights with \\u03B1 = 1, \\u03C1 = 0.5\")\n",
    "display(df_model)\n",
    "\n",
    "#plot setting\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "#first subplot\n",
    "bar = ax.barh(ypos, elastic.coef_, align = 'center', color = 'red')\n",
    "ax.set_yticks(ypos)\n",
    "ax.set_yticklabels(names)\n",
    "ax.set_xlabel('Weight value')\n",
    "ax.set_title('Weights of every feature')\n",
    "\n",
    "#define sliders\n",
    "alpha =  widgets.FloatSlider(value=1, min = 1, max= 100, step= 1, description = \"\\u03B1\")\n",
    "rho =  widgets.FloatSlider(value=0.5, min = 0.01, max= 1, step= 0.01, description = \"\\u03C1\")\n",
    "\n",
    "#define what happens when slider value change\n",
    "def update(alpha, rho):\n",
    "    elastic = ElasticNet(alpha = alpha, l1_ratio = rho)\n",
    "    elastic.fit(X_train, y_train)\n",
    "    for i in range(len(elastic.coef_)):\n",
    "        bar[i].set_width(elastic.coef_[i])\n",
    "    df_model.loc['weights'] = elastic.coef_.tolist()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "# An HBox lays out its children horizontally\n",
    "ui = widgets.HBox([alpha, rho])\n",
    "#define interactive output\n",
    "plot = interactive_output(update, {'alpha':alpha, 'rho':rho})\n",
    "#show slider and plot\n",
    "display(plot,ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a26be",
   "metadata": {},
   "source": [
    "# Come trovare i parametri migliori? \n",
    "\n",
    "Per trovare i **parametri migliori dei modelli, detto anche hyperparameter tuning(poichè chiamati anche iperparametri)** consiste nel trovare dei metodi attraverso cui possiamo stabilire quali siano i valori di $\\alpha$, $\\beta$ o di qualsiasi altro parametro che il nostro modello usa per allenarsi sui dati, per questa trattazione vedremo tre modi : criterio di informazione di Akaike, criterio di informazione Baesiano e Cross validation.\n",
    "\n",
    "## Akaike Information Criterion (AIC)\n",
    "\n",
    "L'__[AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion)__ è un criterio che si basa sulla seguente formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large AIC = 2k - 2\\ln{(\\hat{L})}\n",
    "\\end{equation}\n",
    "\n",
    "dove $k$ indica il numero di parametri del modello, $\\hat{L} = p(x | \\theta, M)$ è il massimo valore di verosomiglianza del modello con x i dati, $\\theta$ i parametri del modello e $M$ il modello stesso, dove il modello migliore è quello che minimizza l'AIC.\n",
    "\n",
    "## Bayesian information criterion(BIC)\n",
    "\n",
    "Il __[BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion)__ invece ha la seguente formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large BIC = k\\ln(n) - 2\\ln{(\\hat{L})}\n",
    "\\end{equation}\n",
    "\n",
    "dove il parametro $n$ indica il numero di dati presenti.\n",
    "\n",
    "## Cross Validation\n",
    "\n",
    "Nel caso della __[Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29)__ queello che usiamo è la __[coordinate descent](https://en.wikipedia.org/wiki/Coordinate_descent)__ dove la formula su cui ci basiamo nel caso la funzione sia differenziabile può essere rappresentata come:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Large x_{i+1} = x_{i} - \\alpha \\frac{\\partial F}{\\partial x_{i}}(\\textbf{x})\n",
    "\\end{equation}\n",
    "\n",
    "in cui $\\alpha$ rappresenta il passo da effettuare nello spazio, la F è la nostra funzione da minimizzare e possiamo decidere di fissarci su una singola componente o su un intero blocco di esse. Usiamo in tal caso la Cross Validation per essere sicuri che i parametri trovati siano effettivamente generali e non specifici al nostro dataset di training.\n",
    "\n",
    "## Least Angle Regression (LARS)\n",
    "\n",
    "La libreria scikit(__[link alla libreria](https://scikit-learn.org/stable/modules/linear_model.html#least-angle-regression)__) permette di usare un particolare algoritmo molto utile chiamato __[LARS](https://en.wikipedia.org/wiki/Least-angle_regression)__, che permette di allenare modelli anche ad alta dimensionalità e che permette di estrapolare le varibili maggiormente correlate al target ed i loro coefficienti, vedremo che con questo algoritmo è possibile applicare i modelli appena visti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9eecc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the data for training and testing\n",
      "Data prepared, the 80% will be used for training, and the remaining 20% will be for testing\n",
      "--------------------------------------------------------------------------------\n",
      "Ridge Model optimized using 10 folds croos validation and searching all integers alphas between 1 and 100\n",
      "Ridge best alpha: 0, R^2 score testing: 0.5892223849182503\n",
      " time taken : 2.002999782562256s\n",
      "--------------------------------------------------------------------------------\n",
      "Lasso Model optimized using 10 folds cross validation and searching all integers alphas between 1 and 100\n",
      "Lasso best alpha: 0.01, R^2 score testing: 0.58499838480617, numero iterazioni: 64\n",
      " time taken : 0.16098308563232422s\n",
      "--------------------------------------------------------------------------------\n",
      "Lasso Model using Lars algorithm optimized using 10 folds cross validation and searching all integers alphas between 1 and 100\n",
      "Lasso Lars best alpha: 0.0009600789694834831, R^2 score testing: 0.5858944312103755, numero iterazioni: 14\n",
      " time taken : 0.05199694633483887s\n",
      "--------------------------------------------------------------------------------\n",
      "Lasso Model using AIC criterion optimization\n",
      "Lasso Lars using AIC best alpha: 0.0001988059860358497, R^2 score testing: 0.5884444412846026, numero iterazioni : 15\n",
      " time taken : 0.007001399993896484s\n",
      "--------------------------------------------------------------------------------\n",
      "Lasso Model using BIC criterion optimization\n",
      "Lasso Lars using BIC best alpha: 0.06987936879637764, R^2 score testing: 0.5047826091816949, numero iterazioni : 15\n",
      " time taken : 0.006998538970947266s\n",
      "--------------------------------------------------------------------------------\n",
      "Elasticnet Model optimized using 10 folds cross validation and searching l1_ratio between 0 and 1\n",
      "Elasticnet best alpha: 0.812788907603632, best l1_ratio: 0.99, R^2 score testing: 0.508981141057887, numero iterazioni: 46\n",
      " time taken : 14.50524616241455s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time #libreria per tenere conto del tempo impiegato\n",
    "from numpy import arange\n",
    "\n",
    "#importiamo i metodi per trovare gli iperparametri\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LassoLarsCV, LassoLarsIC, ElasticNetCV\n",
    "\n",
    "#definiamo i dati da usare\n",
    "X, Y = df.drop('MEDV', axis = 1).values, df.MEDV.values\n",
    "\n",
    "print('Preparing the data for training and testing')\n",
    "#prepare the data for the criterion optimization and testing \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0, test_size = 0.2)\n",
    "print('Data prepared, the 80% will be used for training, and the remaining 20% will be for testing')\n",
    "#separator\n",
    "print('-'*80)\n",
    "\n",
    "#range of alphas to try on ridge\n",
    "alpha = range(0,100,1)\n",
    "betas = arange(0.01, 1, 0.01)\n",
    "\n",
    "#definiamo una Ridge cross validation con score r2 e 10 fold con il nostro insieme di parametri alpha\n",
    "print('Ridge Model optimized using 10 folds croos validation and searching all integers alphas between 1 and 100')\n",
    "ridge = RidgeCV(alphas = alpha, scoring = 'r2', cv = 10)\n",
    "ridge_start = time.time()\n",
    "ridge.fit(X_train, Y_train)\n",
    "ridge_end = time.time()\n",
    "print(f'Ridge best alpha: {ridge.alpha_}, R^2 score testing: {ridge.score(X_test, Y_test)}\\n'\n",
    "      f' time taken : {ridge_end - ridge_start}s')\n",
    "#separator\n",
    "print('-'*80)\n",
    "\n",
    "#Lasso model using cv\n",
    "print('Lasso Model optimized using 10 folds cross validation and searching all integers alphas between 1 and 100')\n",
    "#even in this case you need to pass the number of parameters\n",
    "lassocv = LassoCV(alphas = betas, cv = 10)\n",
    "lassocv_start = time.time()\n",
    "lassocv.fit(X_train, Y_train)\n",
    "lassocv_end = time.time()\n",
    "print(f'Lasso best alpha: {lassocv.alpha_}, R^2 score testing: {lassocv.score(X_test, Y_test)}, ' \n",
    "      f'numero iterazioni: {lassocv.n_iter_}\\n time taken : {lassocv_end - lassocv_start}s')\n",
    "#separator\n",
    "print('-'*80)\n",
    "\n",
    "#lasso using cv and lars\n",
    "print('Lasso Model using Lars algorithm optimized using 10 folds cross validation and searching all integers alphas between 1 and 100')\n",
    "#here i pass the maximum number of of alphas used on the path to compute the residual\n",
    "lassolarscv = LassoLarsCV(max_n_alphas=100, cv = 10)\n",
    "lassolarscv_start = time.time()\n",
    "lassolarscv.fit(X_train, Y_train)\n",
    "lassolarscv_end = time.time()\n",
    "print(f'Lasso Lars best alpha: {lassolarscv.alpha_}, R^2 score testing: {lassolarscv.score(X_test, Y_test)}, '\n",
    "      f'numero iterazioni: {lassolarscv.n_iter_}\\n time taken : {lassolarscv_end - lassolarscv_start}s')\n",
    "#separator\n",
    "print('-'*80)\n",
    "\n",
    "#lasso model using aic\n",
    "print('Lasso Model using AIC criterion optimization')\n",
    "#here i pass the maximum number of of alphas used on the path to compute the residual\n",
    "lassolarsaic = LassoLarsIC(criterion='aic')\n",
    "lassolarsaic_start = time.time()\n",
    "lassolarsaic.fit(X_train,Y_train)\n",
    "lassolarsaic_end = time.time()\n",
    "print(f'Lasso Lars using AIC best alpha: {lassolarsaic.alpha_}, R^2 score testing: {lassolarsaic.score(X_test, Y_test)}, ' \n",
    "      f'numero iterazioni : {lassolarsaic.n_iter_}\\n time taken : {lassolarsaic_end - lassolarsaic_start}s')\n",
    "#separator\n",
    "print('-'*80)\n",
    "\n",
    "\n",
    "#lasso model using bic\n",
    "print('Lasso Model using BIC criterion optimization')\n",
    "#here i pass the maximum number of of alphas used on the path to compute the residual\n",
    "lassolarsbic = LassoLarsIC(criterion='bic')\n",
    "lassolarsbic_start = time.time()\n",
    "lassolarsbic.fit(X_train,Y_train)\n",
    "lassolarsbic_end = time.time()\n",
    "print(f'Lasso Lars using BIC best alpha: {lassolarsbic.alpha_}, R^2 score testing: {lassolarsbic.score(X_test, Y_test)}, ' \n",
    "      f'numero iterazioni : {lassolarsbic.n_iter_}\\n time taken : {lassolarsbic_end - lassolarsbic_start}s')\n",
    "#separator\n",
    "print('-'*80)\n",
    "\n",
    "#Lasso model using cv\n",
    "print('Elasticnet Model optimized using 10 folds cross validation and searching l1_ratio between 0 and 1')\n",
    "#even in this case you need to pass the number of parameters\n",
    "elasticv = ElasticNetCV(l1_ratio=betas, n_alphas=100, cv = 10)\n",
    "elasticv_start = time.time()\n",
    "elasticv.fit(X_train, Y_train)\n",
    "elasticv_end = time.time()\n",
    "print(f'Elasticnet best alpha: {elasticv.alpha_}, best l1_ratio: {elasticv.l1_ratio_}, R^2 score testing: {elasticv.score(X_test, Y_test)}, ' \n",
    "      f'numero iterazioni: {elasticv.n_iter_}\\n time taken : {elasticv_end-  elasticv_start}s')\n",
    "#separator\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446892b",
   "metadata": {},
   "source": [
    "Testando tutti i modelli abbiamo capito che il modello migliore tra quelli visti è **il Lasso, il migliore score nel miglior tempo lo otteniamo usando il criterio AIC**, in genere *se siete decisi tra questi due modelli iniziate con testare il modello Elasticnet, se il termine l1_ratio tende a uno dei due estremi allora crecate i migliori valori per tale modello controllando sempre che il modello abbia **uno score sul testing** più alto del modello iniziale*, __[per maggiori info](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html?highlight=aic)__.\n",
    "Qualora incontraste lunge attese nell'esecuzione in alcuni di questi algortimi è presente l'opzione ***n_jobs*** ponete questo valore uguale a -1 per fare in modo che l'algoritmo usi tutti i core del pc per eseguire le operazioni o un numero compreso tra 1 e il numero di core del vostro pc, ma state attenti che userete molto più risorse!\n",
    "\n",
    "---\n",
    "\n",
    "AVETE FINITO LA LEZIONE SULLA REGRESSIONE LINEARE E LA SUA REGORALIZZAZIONE, A PRESTO!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

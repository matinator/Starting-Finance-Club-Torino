{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89d3cd7-9683-4410-b547-7350113aad11",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "La tecnica di __[clustering](https://it.wikipedia.org/wiki/Clustering)__ consiste in un analisi multivariata dei dati al fine di stabilire dei gruppi contenenti dati simili al loro interno e dati diversi al loro esterno, in genere per effettuare questa misura della somiglianza tra i dati si ricorre a misura di metrica come distanza geometrica, in base ad essa i risultati potrebbero essere diversi.<br>\n",
    "Il clustering presenta due approcci al problema:\n",
    "- approccio aggregativo : ogni punto è un cluster a se e l'algoritmo secondo certe specifiche unisce i cluster più vicini\n",
    "- approccio divisivo: il dataset è un unico cluster e vengono poi definito in seguito più cluster basandoci sulla similarità dei dati\n",
    "**Potete notare che non sono state fatte assunzioni su come quantificare l'errore di mislassificazione ma solo sulle proprietà dei dati, questo ci dice che questi metodi sono unsupervised, ovvero l'agoritmo non richiede di sapere la soluzione corretta**.\n",
    "***Questo è un allo stesso tempo un vantaggio e uno svataggio, lo svantaggio è che l'algoritmo impara autonomamente le proprietà dei dati, lo svantaggio è che è estrememamente difficile valutare e interpretare i risultati ottenuti.***\n",
    "Per ovviare a questi problemi in molti casi si usa un __[clustering gerarchico](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)__, questo permette di definire una struttura ad albero attraverso cui poter interpretare successivamente i dati.\n",
    "\n",
    "## K-Means\n",
    "\n",
    "Partiamo dall'algoritmo forse più conosciuto e citato per il clustering il __[K-means](https://scikit-learn.org/stable/modules/clustering.html#k-means)__, la caratteristica di questo algoritmo è **la necessità di sapere il numero di cluster e il fatto che essi siano isotropi e convessi, cosa che non permette sempre di essere in grado di rivelarsi vera**.<br>\n",
    "L'algoritmo si basa sulla **minimizzazione della somma dei quadrati dei criterio(metrica eucliediana, di manhattan, ecc...) attraverso la scelta di centroidi, ovvero icentri del cluster**, per questi motivi dobbiamo stare a non passare dataset ad alta dimensionalità poichè in tal caso queste somma diventano enormi, per questo in molti casi questo effetto si chiama ***curse of dimensionality***.\n",
    "La velocità con cui l'algoritmo converge e la possibilità di trovare un minimo locale è influita fortemente dalla scelta delle posizioni iniziali dei centroidi, un modo per risolvere il problema è usare l'algoritmo __[k-means++](https://en.wikipedia.org/wiki/K-means%2B%2B)__.<br>I cluster ottenuti alla fine avranno una varianza quanto più uguale possibile tra di loro, vediamo di capire cosa succede se però diamo un numero cluster sbagliato attraverso del codice python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85109410-734b-459f-b186-a66fe6ff414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset we have is made of: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training report classification of Kmeans on iris\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        34\n",
      "           1       0.00      0.00      0.00        27\n",
      "           2       0.17      0.17      0.17        29\n",
      "\n",
      "    accuracy                           0.06        90\n",
      "   macro avg       0.06      0.06      0.06        90\n",
      "weighted avg       0.05      0.06      0.05        90\n",
      "\n",
      "Testing report classification of Kmean on iris\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.29      0.43      0.35        21\n",
      "\n",
      "    accuracy                           0.15        60\n",
      "   macro avg       0.10      0.14      0.12        60\n",
      "weighted avg       0.10      0.15      0.12        60\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157d302587d14007997cd2a2075ba9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers are:\n",
      "[[6.92307692 3.12307692 5.78076923 2.08461538]\n",
      " [4.99411765 3.38235294 1.45294118 0.23235294]\n",
      " [5.85666667 2.75333333 4.29666667 1.39333333]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris # dataset of plants\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "\n",
    "#get the data\n",
    "iris = load_iris()\n",
    "iris_data = load_iris(as_frame=True)\n",
    "#get the pandas dataframe\n",
    "df = iris_data['frame']\n",
    "print('The dataset we have is made of: ')\n",
    "display(df)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data['data'].values, \n",
    "                                                    iris_data['target'].values,\n",
    "                                                    random_state=0, test_size=0.4)\n",
    "\n",
    "#let's train the model\n",
    "iris_kmeans = KMeans(n_clusters=3) #correct number of cluster\n",
    "iris_kmeans.fit(X_train)\n",
    "\n",
    "#classification training report\n",
    "print(\"Training report classification of Kmeans on iris\")\n",
    "print(classification_report(y_train, iris_kmeans.predict(X_train)))\n",
    "\n",
    "#classification teaining report\n",
    "print(\"Testing report classification of Kmean on iris\")\n",
    "print(classification_report(y_test, iris_kmeans.predict(X_test)))\n",
    "\n",
    "#unite predictions\n",
    "kmeans_pred = np.concatenate((iris_kmeans.predict(X_train), iris_kmeans.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax1 = plt.subplot(121, projection='3d', elev=-150, azim=110)\n",
    "ax1.scatter(xs = df['sepal length (cm)'].values, ys = df['sepal width (cm)'].values, \n",
    "           zs = df['petal length (cm)'].values, c=df['target'].values )\n",
    "ax1.set_title(\"Iris dataset\")\n",
    "ax1.set_xlabel('sepal length')\n",
    "ax1.set_ylabel('sepal width')\n",
    "ax1.set_zlabel('petal length')\n",
    "\n",
    "ax2= plt.subplot(122, projection='3d', elev=-150, azim=110)\n",
    "ax2.scatter(xs = df['sepal length (cm)'].values, ys = df['sepal width (cm)'].values, \n",
    "           zs = df['petal length (cm)'].values, c=kmeans_pred )\n",
    "ax2.set_title(\"Predicted dataset KMEANS\")\n",
    "ax2.set_xlabel('sepal length')\n",
    "ax2.set_ylabel('sepal width')\n",
    "ax2.set_zlabel('petal length')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'Cluster centers are:\\n{iris_kmeans.cluster_centers_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a44d92-702e-4c25-a2f3-529ccbbe1394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we try to use the diabetes dataset\n",
      "Training report classification of Kmeans on diabetes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75       393\n",
      "           1       0.52      0.32      0.40       221\n",
      "\n",
      "    accuracy                           0.65       614\n",
      "   macro avg       0.60      0.58      0.57       614\n",
      "weighted avg       0.63      0.65      0.62       614\n",
      "\n",
      "Testing report classification of Kmeans on diabetes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       107\n",
      "           1       0.54      0.32      0.40        47\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.64      0.60      0.60       154\n",
      "weighted avg       0.68      0.71      0.68       154\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e104522add40afaaee0293ca516394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers are:\n",
      "[[  3.96855346 115.18658281  68.34591195  17.68972746  32.63102725\n",
      "   31.44046122   0.43319078  33.71069182]\n",
      " [  3.54744526 140.77372263  72.2919708   30.83941606 254.50364964\n",
      "   34.87445255   0.58234307  33.18978102]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "print(\"Now we try to use the diabetes dataset\")\n",
    "#get diabetes data\n",
    "diabetes = pd.read_csv('../data/diabetes2.csv')\n",
    "X_diabetes, y_diabetes = diabetes.drop('Outcome', axis = 1).values, diabetes.Outcome.values\n",
    "\n",
    "X_diab_train, X_diab_test, y_diab_train, y_diab_test = train_test_split(X_diabetes, \n",
    "                                                    y_diabetes,\n",
    "                                                    random_state=0, test_size=0.2)\n",
    "\n",
    "#ler's train the model\n",
    "diab_kmeans = KMeans(n_clusters=2) #correct number of cluster\n",
    "diab_kmeans.fit(X_diab_train)\n",
    "\n",
    "#classification training report\n",
    "print(\"Training report classification of Kmeans on diabetes\")\n",
    "print(classification_report(y_diab_train, diab_kmeans.predict(X_diab_train)))\n",
    "\n",
    "#classification teaining report\n",
    "print(\"Testing report classification of Kmeans on diabetes\")\n",
    "print(classification_report(y_diab_test, diab_kmeans.predict(X_diab_test)))\n",
    "\n",
    "#unite predictions\n",
    "kmeans_pred_diab = np.concatenate((diab_kmeans.predict(X_diab_train), diab_kmeans.predict(X_diab_test)))\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "ax3 = plt.subplot(121, projection='3d', elev=-150, azim=110)\n",
    "ax3.scatter(xs = diabetes['BMI'].values, ys = diabetes['Glucose'].values, \n",
    "           zs = diabetes['Age'].values, c=y_diabetes )\n",
    "ax3.set_title(\"Diabetes dataset\")\n",
    "ax3.set_xlabel('BMI')\n",
    "ax3.set_ylabel('Glucose')\n",
    "ax3.set_zlabel('Age')\n",
    "\n",
    "ax4 = plt.subplot(122, projection='3d', elev=-150, azim=110)\n",
    "ax4.scatter(xs = diabetes['BMI'].values, ys = diabetes['Glucose'].values, \n",
    "           zs = diabetes['Age'].values, c=kmeans_pred_diab )\n",
    "ax4.set_title(\"Predicted dataset KMEANS\")\n",
    "ax4.set_xlabel('BMI')\n",
    "ax4.set_ylabel('Glucose')\n",
    "ax4.set_zlabel('Age')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'Cluster centers are:\\n{diab_kmeans.cluster_centers_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92f652-65f2-4d6a-a147-28c6cc03c8b5",
   "metadata": {},
   "source": [
    "Come possiamo vedere in tal caso la situazione non è così buona, nè ottimale, questo è dovuto al fatto che noi non abbiamo dei cluster isotropi e non sono convessi, infatti si sovrappongono molto spesso uno con l'altro.<br>\n",
    "Ci possiamo mettere a usare altri algoritmi come __[Spectral clusteing](https://scikit-learn.org/stable/modules/clustering.html#spectral-clustering)__, __[BIRCH](https://scikit-learn.org/stable/modules/clustering.html#birch)__ e altri oppure preprocessare il dataset, quello che però ci possiamo chiesere è **qualora io però non sappia il numero di cluster posso usare algoritmo che non lo richiedano? La risposta è SI, esistono questi lgoritmi tra questi in scikit ci sono:** __[Affinity propagation](%matplotlib widget)__,  __[DBSCAN](https://scikit-learn.org/stable/modules/clustering.html#dbscan)__, __[OPTICS](https://scikit-learn.org/stable/modules/clustering.html#optics)__ e altri, in questo notebook farò vedere solo il DBSCAN.\n",
    "\n",
    "## DBSCAN\n",
    "\n",
    "Il __[DBSCAN](https://it.wikipedia.org/wiki/Dbscan)__ acronimo per \"Density-Based Spatial Clustering of Applications with Noise\" è un algoritmo di clustering il cui obiettivo e di dividere le regioni dello spazio in zone ad altà densità circondate da zone a bassa densità, per fare ciò il DBSCAN usa dei parametridi densità attraverso cui riesce a definire dei core samples che saranno il nostro cluster.<br>\n",
    "Controllando i valori dei parametri possiamo rendere l'algoritmo più robusto rispetto al Noise che ci permette di definire anche quando alcuni punti che non appartengono ai cluster siano effettivamente outliers, notate bene che a differenza dei kmeans questo algoritmo non richiede alcuna ipotesi sulla forma che abbiano questi cluster. L'implementazione scikit la trovate __[qui](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)__, consultate anche la __[user guide di scikit](https://scikit-learn.org/stable/modules/clustering.html#dbscan)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d74110-bfcb-4ef0-acde-a125c34623b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of DBSCAN on iris\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       1.00      0.98      0.99        50\n",
      "           1       0.52      0.88      0.66        50\n",
      "           2       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.62       150\n",
      "   macro avg       0.38      0.46      0.41       150\n",
      "weighted avg       0.51      0.62      0.55       150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48932fe22ee4d2e938e0604ef45a1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(n_jobs=-1)#all cores\n",
    "\n",
    "#classification training report\n",
    "print(\"Classification of DBSCAN on iris\")\n",
    "print(classification_report(iris_data['target'].values, dbscan.fit_predict(iris_data['data'].values)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax1 = plt.subplot(121, projection='3d', elev=-150, azim=110)\n",
    "ax1.scatter(xs = df['sepal length (cm)'].values, ys = df['sepal width (cm)'].values, \n",
    "           zs = df['petal length (cm)'].values, c=df['target'].values )\n",
    "ax1.set_title(\"Iris dataset\")\n",
    "ax1.set_xlabel('sepal length')\n",
    "ax1.set_ylabel('sepal width')\n",
    "ax1.set_zlabel('petal length')\n",
    "\n",
    "ax2= plt.subplot(122, projection='3d', elev=-150, azim=110)\n",
    "ax2.scatter(xs = df['sepal length (cm)'].values, ys = df['sepal width (cm)'].values, \n",
    "           zs = df['petal length (cm)'].values, c=dbscan.fit_predict(iris_data['data'].values) )\n",
    "ax2.set_title(\"Predicted dataset DBSCAN\")\n",
    "ax2.set_xlabel('sepal length')\n",
    "ax2.set_ylabel('sepal width')\n",
    "ax2.set_zlabel('petal length')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c2ea993-fd6c-4072-adea-eee68405006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of DBSCAN on diabetes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       0.0\n",
      "           0       0.00      0.00      0.00     500.0\n",
      "           1       0.00      0.00      0.00     268.0\n",
      "\n",
      "    accuracy                           0.00     768.0\n",
      "   macro avg       0.00      0.00      0.00     768.0\n",
      "weighted avg       0.00      0.00      0.00     768.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b645dfd197248c4921486bd7e2a6772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#classification training report\n",
    "print(\"Classification of DBSCAN on diabetes\")\n",
    "print(classification_report(y_diabetes, dbscan.fit_predict(X_diabetes)))\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "ax3 = plt.subplot(121, projection='3d', elev=-150, azim=110)\n",
    "ax3.scatter(xs = diabetes['BMI'].values, ys = diabetes['Glucose'].values, \n",
    "           zs = diabetes['Age'].values, c=y_diabetes )\n",
    "ax3.set_title(\"Diabetes dataset\")\n",
    "ax3.set_xlabel('BMI')\n",
    "ax3.set_ylabel('Glucose')\n",
    "ax3.set_zlabel('Age')\n",
    "\n",
    "ax4 = plt.subplot(122, projection='3d', elev=-150, azim=110)\n",
    "ax4.scatter(xs = diabetes['BMI'].values, ys = diabetes['Glucose'].values, \n",
    "           zs = diabetes['Age'].values, c=dbscan.fit_predict(X_diabetes) )\n",
    "ax4.set_title(\"Predicted dataset DBSCAN\")\n",
    "ax4.set_xlabel('BMI')\n",
    "ax4.set_ylabel('Glucose')\n",
    "ax4.set_zlabel('Age')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d62f2-2e30-4a80-913d-598f29828379",
   "metadata": {},
   "source": [
    "Come possiamo vedere il DBSCAN in alcuni dataset è in grado di fare un lavoro discreto come nell'iris, ma purtroppo per altri tipi di dataset come diabetes non lo fa poiché la densità dei dataset è troppo significativa per poter definire ulteriori cluster, per provare a ottenere soluzioni migliori potete impostare diversi valori di `min_samples` e `eps` oppure cambiare l'ordine dei dati che influisce sulla creazione dei cluster.<br>\n",
    "Negli algoritmi agglomerativi è possibile avere un __[dendogramma](https://it.wikipedia.org/wiki/Dendrogramma)__ attraverso cui è possibile visualizzare l'albero di separazione, potete guardare __[questo esempio scikit](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)__.<br>\n",
    "Per avere una visione più generale del problema potete anche guardare come si comportano i diversi algoritmi scikit __[qui](https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods)__, inoltre per saperne di più sul clustering in scikit consultate __[la sezione scikit](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)__.\n",
    "\n",
    "***\n",
    "\n",
    "COMPLIMENTO AVETE FINITO IL NOTEBOOK SUL CLUSTERING A PRESTO!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
